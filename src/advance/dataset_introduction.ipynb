{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dataset module introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup following http://docs.chainer.org/en/stable/tutorial/basic.html\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "import chainer.dataset\n",
    "import chainer.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in dataset modules\n",
    "\n",
    "Some dataset format is already implemented in `chainer.datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TupleDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'chainer.datasets.tuple_dataset.TupleDataset'>, len: 10\n"
     ]
    }
   ],
   "source": [
    "from chainer.datasets import TupleDataset\n",
    "\n",
    "x = np.arange(10)\n",
    "t = x * x\n",
    "\n",
    "data = TupleDataset(x, t)\n",
    "\n",
    "print('data type: {}, len: {}'.format(type(data), len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TupleDataset' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4d6baf1a67bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TupleDataset' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Unlike numpy, it does not have shape property.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i`-th data can be accessed by `data[i]`\n",
    "\n",
    "which is a tuple of format ($x_i$, $t_i$, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get forth data -> x=3, t=9\n",
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice accessing\n",
    "\n",
    "When TupleDataset is accessed by slice indexing, e.g. `data[i:j]`, returned value is __list of tuple__\n",
    "$[(x_i, t_i), ..., (x_{j-1}, t_{j-1})]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 4), (3, 9)]\nexamples type: <class 'list'>, len: 4\n"
     ]
    }
   ],
   "source": [
    "# Get 1st, 2nd, 3rd data at the same time.\n",
    "examples = data[0:4]\n",
    "\n",
    "print(examples)\n",
    "print('examples type: {}, len: {}'\n",
    "      .format(type(examples), len(examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert examples into minibatch format, you can use `concat_examples` function in `chainer.dataset`.\n",
    "\n",
    "Its return value is in format `([x_array], [t array], ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_minibatch = [0 1 2 3], type: <class 'numpy.ndarray'>, shape: (4,)\nt_minibatch = [0 1 4 9], type: <class 'numpy.ndarray'>, shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "from chainer.dataset import concat_examples\n",
    "\n",
    "data_minibatch = concat_examples(examples)\n",
    "\n",
    "#print(data_minibatch)\n",
    "#print('data_minibatch type: {}, len: {}'\n",
    "#      .format(type(data_minibatch), len(data_minibatch)))\n",
    "\n",
    "x_minibatch, t_minibatch = data_minibatch\n",
    "# Now it is array format, which has shape\n",
    "print('x_minibatch = {}, type: {}, shape: {}'.format(x_minibatch, type(x_minibatch), x_minibatch.shape))\n",
    "print('t_minibatch = {}, type: {}, shape: {}'.format(t_minibatch, type(t_minibatch), t_minibatch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DictDataset\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important point is that `get_example` function is called every time when the data is accessed by [] indexing.\n",
    "\n",
    "Thus you may put random value generation for data augmentation code in get_example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataset\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a concrete example to create new dataset from original tuple dataset by adding a small noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabeledImageDataset\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert examples into minibatch format, you can use `concat_examples` function in `chainer.dataset` in the sameway explained at TupleDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubDataset\n",
    "\n",
    "TBD\n",
    "\n",
    "It can be used for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.split_dataset_n_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your own custom dataset\n",
    "\n",
    "You can define your own dataset by implementing a sub class of `DatasetMixin` in `chainer.dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatasetMixin\n",
    "\n",
    "If you want to define custom dataset, `DatasetMixin` provides the base function to make compatible with other dataset format.\n",
    "\n",
    "Another important usage for `DatasetMixin` is to __preprocess__ the input data, including __data augmentation__.\n",
    "\n",
    "To implement subclass of `DatasetMixin`, you usually need to implement these 3 functions.\n",
    " - Override `__init__(self, *args)` function: It is not compulsary but\n",
    " - Override `__len__(self)` function        : Iterator need to know the length of this dataset to understand the end of epoch.\n",
    " - Override `get_examples(self, i)` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.dataset import DatasetMixin\n",
    "\n",
    "\n",
    "print_debug = True\n",
    "class SimpleDataset(DatasetMixin):\n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        if print_debug: \n",
    "            print('get_example, i = {}'.format(i))\n",
    "        return self.values[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important function in `DatasetMixin` is `get_examples(self, i)` function. \n",
    "This function is called when they access data[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data = SimpleDataset([0, 1, 4, 9, 16, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_example, i = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_example(self, i) is called when data is accessed by data[i]\n",
    "simple_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_example, i = 1\nget_example, i = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data can be accessed using slice indexing as well\n",
    "\n",
    "simple_data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important point is that `get_example` function is called every time when the data is accessed by [] indexing.\n",
    "\n",
    "Thus you may put random value generation for data augmentation code in get_example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer.dataset import DatasetMixin\n",
    "\n",
    "print_debug = False\n",
    "\n",
    "\n",
    "def calc(x):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "class SquareNoiseDataset(DatasetMixin):\n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        if print_debug: \n",
    "            print('get_example, i = {}'.format(i))\n",
    "        x = self.values[i]\n",
    "        t = calc(x) \n",
    "        t_noise = t + np.random.normal(0, 0.1)\n",
    "        return x, t_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_noise_data = SquareNoiseDataset(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below `SimpleNoiseDataset` adds small Gaussian noise to the original value,\n",
    "and every time the value is accessed, `get_example` is called and differenct noise is added even if you access to the data with same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing square_noise_data[3]\n1st:  (3, 9.2819845958846461)\n2nd:  (3, 8.8891164834607377)\n3rd:  (3, 8.9558600783664595)\n"
     ]
    }
   ],
   "source": [
    "# Accessing to the same index, but the value is different!\n",
    "print('Accessing square_noise_data[3]', )\n",
    "print('1st: ', square_noise_data[3])\n",
    "print('2nd: ', square_noise_data[3])\n",
    "print('3rd: ', square_noise_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing square_noise_data[0:4]\n1st:  [(0, -0.11465820953532918), (1, 1.0652752646373151), (2, 3.8295759509448666), (3, 8.8347514838735872)]\n2nd:  [(0, 0.094033330171766155), (1, 0.89304583140240168), (2, 3.9135077150785431), (3, 8.7598211647390194)]\n3rd:  [(0, 0.094427684579741974), (1, 1.0638976835182377), (2, 3.86773676682447), (3, 9.1075182057573691)]\n"
     ]
    }
   ],
   "source": [
    "# Same applies for slice index accessing.\n",
    "print('Accessing square_noise_data[0:4]')\n",
    "print('1st: ', square_noise_data[0:4])\n",
    "print('2nd: ', square_noise_data[0:4])\n",
    "print('3rd: ', square_noise_data[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert examples into minibatch format, you can use `concat_examples` function in `chainer.dataset` in the sameway explained at TupleDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_minibatch = [0 1 2 3], type: <class 'numpy.ndarray'>, shape: (4,)\nt_minibatch = [ 0.03676176  1.0472368   4.04931546  8.98907645], type: <class 'numpy.ndarray'>, shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "from chainer.dataset import concat_examples\n",
    "\n",
    "examples = square_noise_data[0:4]\n",
    "data_minibatch = concat_examples(examples)\n",
    "\n",
    "x_minibatch, t_minibatch = data_minibatch\n",
    "# Now it is array format, which has shape\n",
    "print('x_minibatch = {}, type: {}, shape: {}'.format(x_minibatch, type(x_minibatch), x_minibatch.shape))\n",
    "print('t_minibatch = {}, type: {}, shape: {}'.format(t_minibatch, type(t_minibatch), t_minibatch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformDataset\n",
    "\n",
    "Transform dataset can be used to create/modify dataset from existing dataset.\n",
    "New (modified) dataset can be created by `TransformDataset(original_data, transform_function)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a concrete example to create new dataset from original tuple dataset by adding a small noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TransformDataset'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bd973a1d51c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTransformDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TransformDataset'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from chainer.datasets import TransformDataset\n",
    "\n",
    "x = np.arange(10)\n",
    "t = x * x - x\n",
    "\n",
    "original_dataset = TupleDataset(x, t)\n",
    "\n",
    "def transform_function(in_data):\n",
    "    x_i, t_i = in_data\n",
    "    new_t_i = t_i + np.random.normal(0, 0.1)\n",
    "    return x_i, new_t_i\n",
    "\n",
    "transformed_dataset = TransformDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}